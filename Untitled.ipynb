{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad8e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5138d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368e475e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/itetnas04/data-scratch-01/fencai/data/diora\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9157f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            return self.word2idx['<unk>']\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d22f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pytorch/data/partit_data/partnet.dict.pkl', 'rb') as r:\n",
    "    x = pickle.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d995d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Vocabulary at 0x7faa243cbb50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6c2e3",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "76c29f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.chair aaff8d73 model.step_329900.pt 1380e247 [all: ab1811e0 / 06db957b / 14126ca7]\n",
    "# 1.table aea84162 model.step_317900.pt b3d65fcf [all: 1cc2528f / d42498e3 / 22f0f3e5]\n",
    "# 2.bed e81dd9de model.step_57900.pt d43523b6 [all: 408181da / 2e1de6e1 / ea6511bd]\n",
    "# 3.bag 9149db2e model.step_25900.pt 4bbd9841 [all: 4bb6f870 / 12b06d81 / 56c1faa4]\n",
    "\n",
    "# 0.chair 037dee7e\n",
    "# 1.table 1229d735\n",
    "# 2.bed d66314ad\n",
    "# 3.bag 87bf56b8\n",
    "\n",
    "path = './log/87bf56b8/parse.jsonl'\n",
    "type_ = '3.bag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4925997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path, 'r') as f:\n",
    "    lines = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "24555e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_res = [\n",
    "    json.loads(l) for l in lines\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "edee791f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', [['is', 'a'], ['bag', 'with']]], ['a', 'body']]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_res[0]['tree'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2d61c066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['and', ['a', ['single', 'handle']]], [['at', 'the'], 'top']]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_res[0]['tree'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c5f2e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_len(tree):\n",
    "    if isinstance(tree, str):\n",
    "        return 1\n",
    "\n",
    "    return sum([get_len(x) for x in tree])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "be495e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_len(lines_res[0]['tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "63905abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bfs\n",
    "def get_spans(tree):\n",
    "    queue = [(tree, 0)]\n",
    "    spans = []\n",
    "\n",
    "    while queue:\n",
    "        current_node = queue.pop(0)\n",
    "\n",
    "        tree = current_node[0]\n",
    "        offset = current_node[1]\n",
    "\n",
    "        spans.append((offset, offset + get_len(tree)-1))\n",
    "\n",
    "        if not isinstance(tree[0], str):\n",
    "            queue.append((tree[0], offset))\n",
    "\n",
    "        if not isinstance(tree[1], str):\n",
    "            queue.append((tree[1], offset + get_len(tree[0])))\n",
    "    return set(spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b19955f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(span1, span2):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for span in span1:\n",
    "        if span in span2:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    for span in span2:\n",
    "        if span not in span1:\n",
    "            fn += 1\n",
    "#     print('tp: {}; fp: {}; fn: {}'.format(tp, fp, fn))\n",
    "    return tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "16277c6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec_txt:  0.42033898305084744\n",
      "recall_txt:  0.42033898305084744\n",
      "corpus_f1_txt:  0.42033898305084744\n",
      "sent_f1_txt:  0.42260239227647994\n"
     ]
    }
   ],
   "source": [
    "sent_f1_txt, corpus_f1_txt = [], [0., 0., 0.]\n",
    "\n",
    "for idx, line in enumerate(lines_res):\n",
    "    pred_txt = get_spans(line['tree'])\n",
    "    example_id = line['example_id']\n",
    "    with open(os.path.join(f'pytorch/data/partit_data/{type_}/test/', example_id, 'lan_spans.txt'), 'r') as w:\n",
    "        gold_txt = json.loads(w.read())\n",
    "    gold_txt = set([(a, b) for a, b in gold_txt])\n",
    "    \n",
    "    tp_txt, fp_txt, fn_txt = get_stats(pred_txt, gold_txt) \n",
    "    corpus_f1_txt[0] += tp_txt\n",
    "    corpus_f1_txt[1] += fp_txt\n",
    "    corpus_f1_txt[2] += fn_txt\n",
    "\n",
    "    overlap_txt = pred_txt.intersection(gold_txt)\n",
    "    prec_txt = float(len(overlap_txt)) / (len(pred_txt) + 1e-8)\n",
    "    reca_txt = float(len(overlap_txt)) / (len(gold_txt) + 1e-8)\n",
    "\n",
    "    if len(gold_txt) == 0:\n",
    "        reca_txt = 1. \n",
    "        if len(pred_txt) == 0:\n",
    "            prec_txt = 1.\n",
    "    f1_txt = 2 * prec_txt * reca_txt / (prec_txt + reca_txt + 1e-8)\n",
    "    sent_f1_txt.append(f1_txt)\n",
    "\n",
    "tp_txt, fp_txt, fn_txt = corpus_f1_txt  \n",
    "prec_txt = tp_txt / (tp_txt + fp_txt)\n",
    "recall_txt = tp_txt / (tp_txt + fn_txt)\n",
    "corpus_f1_txt = 2 * prec_txt * recall_txt / (prec_txt + recall_txt) if prec_txt + recall_txt > 0 else 0.\n",
    "sent_f1_txt = np.mean(np.array(sent_f1_txt))\n",
    "print('prec_txt: ', prec_txt)\n",
    "print('recall_txt: ', recall_txt)\n",
    "print('corpus_f1_txt: ', corpus_f1_txt)\n",
    "print('sent_f1_txt: ', sent_f1_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "40b3f145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is 42\n"
     ]
    }
   ],
   "source": [
    "variable = 42\n",
    "user_input = \"The answer is {variable}\"\n",
    "user_input_formatted = user_input.format(variable=variable)\n",
    "print(user_input_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2783a71",
   "metadata": {},
   "source": [
    "## Check the coverage between train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1b4c53e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = f'./pytorch/data/partit_data//train/'.format(type_)\n",
    "dir_list = [x for x in os.listdir(file_dir) if '.' not in x]\n",
    "textfile_list = [\n",
    "    os.path.join(file_dir, dir_name, 'utterance.txt') for dir_name in dir_list\n",
    "]\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for textfile in textfile_list:\n",
    "    with open(textfile, 'r') as r:\n",
    "        sentences.append(r.read().replace(\".\", \"\").replace(\",\", \" , \").replace(\":\", \" : \").replace(\";\", \" ; \").replace(\"/\", \" \").replace(\"\\'\", \" \\'\").replace(\"\\\"\", \" \\\"\").strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2c7bcbd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_train_set = set([tk for tks in sentences for tk in tks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5e6c01fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1480"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8d788fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = './pytorch/data/partit_data/0.chair/test/'\n",
    "dir_list = [x for x in os.listdir(file_dir) if '.' not in x]\n",
    "textfile_list = [\n",
    "    os.path.join(file_dir, dir_name, 'utterance.txt') for dir_name in dir_list\n",
    "]\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for textfile in textfile_list:\n",
    "    with open(textfile, 'r') as r:\n",
    "        sentences.append(r.read().replace(\".\", \"\").replace(\",\", \" , \").replace(\":\", \" : \").replace(\";\", \" ; \").replace(\"/\", \" \").replace(\"\\'\", \" \\'\").replace(\"\\\"\", \" \\\"\").strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "19f329cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_test_set = set([tk for tks in sentences for tk in tks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0fd002f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "696"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8db91ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_train_set.intersection(word_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bebf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
